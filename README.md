This project turns a simple wine-quality notebook into a tidy, production-style MLOps pipeline. I pulled the training logic into a reusable train.py script so the process is repeatable and versionable. It loads winequality.csv, applies the same preprocessing as the notebook, trains a Random Forest (the best scorer there), and saves both the model and scaler for later use—exactly the kind of discipline you want when moving beyond ad-hoc experiments.

For serving, I wrapped the model in a FastAPI app (main.py) and added a minimal index.html so anyone can try predictions in a browser. Everything is containerized via the Dockerfile, which means it runs the same on your laptop, a VM, or a cluster—no dependency drama, just build and run.

You can spin it up locally (install requirements, run train.py, then uvicorn) or go straight to Docker (docker build and docker run). It’s intentionally lean: no extra feature engineering, no heavy hyperparameter tuning, and basic error handling—for clarity over complexity. The result is a clean, end-to-end example of taking an ML idea to a deployable web app.
